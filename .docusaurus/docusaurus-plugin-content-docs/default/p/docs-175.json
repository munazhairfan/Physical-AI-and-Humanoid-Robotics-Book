{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"category","label":"Introduction","items":[{"type":"link","href":"/docs/intro/preface","label":"Preface","docId":"intro/preface","unlisted":false},{"type":"link","href":"/docs/intro/how-to-use","label":"How to Use This Book","docId":"intro/how-to-use","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1 — Perception & Computer Vision","items":[{"type":"link","href":"/docs/module-1/overview","label":"Module 1: Perception & Computer Vision - Overview","docId":"module-1/overview","unlisted":false},{"type":"link","href":"/docs/module-1/core-concepts","label":"Module 1: Perception & Computer Vision - Core Concepts","docId":"module-1/core-concepts","unlisted":false},{"type":"link","href":"/docs/module-1/architecture","label":"Module 1: Perception & Computer Vision - Architecture","docId":"module-1/architecture","unlisted":false},{"type":"link","href":"/docs/module-1/algorithms","label":"Module 1: Perception & Computer Vision - Algorithms","docId":"module-1/algorithms","unlisted":false},{"type":"link","href":"/docs/module-1/assignments","label":"Assignments","docId":"module-1/assignments","unlisted":false},{"type":"link","href":"/docs/module-1/summary","label":"Summary","docId":"module-1/summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2 — Robotic Nervous System (ROS2)","items":[{"type":"link","href":"/docs/module-2/overview","label":"Overview","docId":"module-2/overview","unlisted":false},{"type":"link","href":"/docs/module-2/core-concepts","label":"Module 2: Robotic Nervous System (ROS2) - Core Concepts","docId":"module-2/core-concepts","unlisted":false},{"type":"link","href":"/docs/module-2/architecture","label":"Module 2: Robotic Nervous System (ROS2) - Architecture","docId":"module-2/architecture","unlisted":false},{"type":"link","href":"/docs/module-2/nodes-topics-services","label":"Module 2: Robotic Nervous System (ROS2) - Nodes, Topics, Services","docId":"module-2/nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-2/qos-dds","label":"Module 2: Robotic Nervous System (ROS2) - QoS and DDS","docId":"module-2/qos-dds","unlisted":false},{"type":"link","href":"/docs/module-2/assignments","label":"Assignments","docId":"module-2/assignments","unlisted":false},{"type":"link","href":"/docs/module-2/summary","label":"Summary","docId":"module-2/summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3 — AI Perception & Sensor Fusion","items":[{"type":"link","href":"/docs/module-3/overview","label":"Overview","docId":"module-3/overview","unlisted":false},{"type":"link","href":"/docs/module-3/core-concepts","label":"Core Concepts","docId":"module-3/core-concepts","unlisted":false},{"type":"link","href":"/docs/module-3/sensors","label":"Sensors","docId":"module-3/sensors","unlisted":false},{"type":"link","href":"/docs/module-3/perception-algorithms","label":"Perception Algorithms","docId":"module-3/perception-algorithms","unlisted":false},{"type":"link","href":"/docs/module-3/fusion-techniques","label":"Fusion Techniques","docId":"module-3/fusion-techniques","unlisted":false},{"type":"link","href":"/docs/module-3/assignments","label":"Assignments","docId":"module-3/assignments","unlisted":false},{"type":"link","href":"/docs/module-3/summary","label":"Summary","docId":"module-3/summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4 — Reinforcement Learning & Control","items":[{"type":"link","href":"/docs/module-4/overview","label":"Module 4: Reinforcement Learning & Control","docId":"module-4/overview","unlisted":false},{"type":"link","href":"/docs/module-4/rl-basics","label":"Module 4: RL Basics","docId":"module-4/rl-basics","unlisted":false},{"type":"link","href":"/docs/module-4/advanced-techniques","label":"Module 4: Advanced RL Techniques","docId":"module-4/advanced-techniques","unlisted":false},{"type":"link","href":"/docs/module-4/control-integration","label":"Module 4: Control Integration","docId":"module-4/control-integration","unlisted":false},{"type":"link","href":"/docs/module-4/assignments","label":"Module 4: Assignments","docId":"module-4/assignments","unlisted":false},{"type":"link","href":"/docs/module-4/summary","label":"Module 4: Summary","docId":"module-4/summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"RAG Chatbot","items":[{"type":"link","href":"/docs/rag-chatbot/embedding","label":"RAG Chatbot: Embedding","docId":"rag-chatbot/embedding","unlisted":false},{"type":"link","href":"/docs/rag-chatbot/api","label":"RAG Chatbot: API","docId":"rag-chatbot/api","unlisted":false},{"type":"link","href":"/docs/rag-chatbot/ui-integration","label":"RAG Chatbot: UI Integration","docId":"rag-chatbot/ui-integration","unlisted":false},{"type":"link","href":"/docs/rag-chatbot/deployment","label":"RAG Chatbot: Deployment","docId":"rag-chatbot/deployment","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Appendix","items":[{"type":"link","href":"/docs/appendix/glossary","label":"Glossary","docId":"appendix/glossary","unlisted":false},{"type":"link","href":"/docs/appendix/references","label":"References","docId":"appendix/references","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"appendix/glossary":{"id":"appendix/glossary","title":"Glossary","description":"Comprehensive glossary of terms used in Physical AI & Humanoid Robotics","sidebar":"docs"},"appendix/references":{"id":"appendix/references","title":"References","description":"Comprehensive list of references and citations used in Physical AI & Humanoid Robotics textbook","sidebar":"docs"},"intro/how-to-use":{"id":"intro/how-to-use","title":"How to Use This Book","description":"Guide to navigating and using the Physical AI & Humanoid Robotics textbook","sidebar":"docs"},"intro/preface":{"id":"intro/preface","title":"Preface","description":"Preface to the Physical AI & Humanoid Robotics textbook","sidebar":"docs"},"module-1/algorithms":{"id":"module-1/algorithms","title":"Module 1: Perception & Computer Vision - Algorithms","description":"Key algorithms in perception and computer vision for robotics","sidebar":"docs"},"module-1/architecture":{"id":"module-1/architecture","title":"Module 1: Perception & Computer Vision - Architecture","description":"System architecture for perception and computer vision in robotics","sidebar":"docs"},"module-1/assignments":{"id":"module-1/assignments","title":"ROS2 Assignments","description":"This section contains assignments organized by difficulty level: beginner, intermediate, and advanced. Each assignment includes expected output or validation checkpoints.","sidebar":"docs"},"module-1/core-concepts":{"id":"module-1/core-concepts","title":"Module 1: Perception & Computer Vision - Core Concepts","description":"Core concepts in perception and computer vision for robotics","sidebar":"docs"},"module-1/diagrams/action-workflow":{"id":"module-1/diagrams/action-workflow","title":"Action Workflow Diagram","description":"This diagram illustrates the workflow of ROS2 actions, which are used for long-running tasks that may provide feedback and can be canceled."},"module-1/diagrams/multi-robot-comm":{"id":"module-1/diagrams/multi-robot-comm","title":"Multi-Robot Communication Graph Diagram","description":"This diagram illustrates how multiple robots can communicate with each other and with centralized systems in a ROS2 environment."},"module-1/diagrams/service-handshake":{"id":"module-1/diagrams/service-handshake","title":"Service Handshake Diagram","description":"This diagram illustrates the request/response communication pattern in ROS2 using services."},"module-1/diagrams/topic-flow":{"id":"module-1/diagrams/topic-flow","title":"Topic Communication Flow Diagram","description":"This diagram illustrates the communication flow between publishers and subscribers in ROS2 using topics."},"module-1/examples/launch-files":{"id":"module-1/examples/launch-files","title":"Launch Files Example","description":"This example demonstrates how to create and use launch files in ROS2 to manage complex robot systems with multiple nodes."},"module-1/examples/publisher-subscriber":{"id":"module-1/examples/publisher-subscriber","title":"Publisher/Subscriber Example","description":"This example demonstrates the fundamental communication pattern in ROS2 using publishers and subscribers. This is the backbone of ROS2's distributed communication system."},"module-1/examples/services-actions":{"id":"module-1/examples/services-actions","title":"Services and Actions Example","description":"This example demonstrates the synchronous communication pattern using Services and the long-running task pattern using Actions in ROS2."},"module-1/overview":{"id":"module-1/overview","title":"Module 1: Perception & Computer Vision - Overview","description":"Overview of perception and computer vision fundamentals for robotics","sidebar":"docs"},"module-1/summary":{"id":"module-1/summary","title":"ROS2 Module Summary","description":"Overview","sidebar":"docs"},"module-2/architecture":{"id":"module-2/architecture","title":"Module 2: Robotic Nervous System (ROS2) - Architecture","description":"System architecture for ROS2-based robotic communication","sidebar":"docs"},"module-2/assignments":{"id":"module-2/assignments","title":"Assignments - Perception & Computer Vision","description":"Practical assignments for the Perception & Computer Vision module","sidebar":"docs"},"module-2/core-concepts":{"id":"module-2/core-concepts","title":"Module 2: Robotic Nervous System (ROS2) - Core Concepts","description":"Core concepts of ROS2 framework and robotic communication","sidebar":"docs"},"module-2/deep-vision":{"id":"module-2/deep-vision","title":"Deep Vision and Neural Networks","description":"Deep learning approaches to computer vision for robotic applications"},"module-2/examples/camera-stream":{"id":"module-2/examples/camera-stream","title":"Camera Stream Processing","description":"Processing real-time camera streams for robotic perception"},"module-2/examples/image-filtering":{"id":"module-2/examples/image-filtering","title":"Image Filtering Pipelines","description":"Complete image filtering pipelines for robotic vision applications"},"module-2/examples/object-detection":{"id":"module-2/examples/object-detection","title":"Object Detection Workflows","description":"Using pre-trained models for object detection in robotic applications"},"module-2/fundamentals":{"id":"module-2/fundamentals","title":"Fundamentals of Robotic Perception","description":"Mathematical foundations and theory of robotic perception"},"module-2/image-processing":{"id":"module-2/image-processing","title":"Image Processing Techniques","description":"Fundamental image processing techniques for robotic vision"},"module-2/mermaid-setup":{"id":"module-2/mermaid-setup","title":"Mermaid Diagram Setup for Documentation","description":"Docusaurus Mermaid Integration"},"module-2/nodes-topics-services":{"id":"module-2/nodes-topics-services","title":"Module 2: Robotic Nervous System (ROS2) - Nodes, Topics, Services","description":"Core communication mechanisms in ROS2: nodes, topics, and services","sidebar":"docs"},"module-2/overview":{"id":"module-2/overview","title":"Overview of Perception & Computer Vision","description":"Introduction to robotic perception and computer vision fundamentals","sidebar":"docs"},"module-2/qos-dds":{"id":"module-2/qos-dds","title":"Module 2: Robotic Nervous System (ROS2) - QoS and DDS","description":"Quality of Service and Data Distribution Service in ROS2","sidebar":"docs"},"module-2/sensors":{"id":"module-2/sensors","title":"Sensor Technologies in Robotics","description":"Overview of different sensor types used in robotic perception"},"module-2/setup-ros2":{"id":"module-2/setup-ros2","title":"ROS2 Setup for Perception & Computer Vision Module","description":"Installing ROS2"},"module-2/summary":{"id":"module-2/summary","title":"Summary and Next Steps","description":"Summary of the Perception & Computer Vision module and connections to broader robotics curriculum","sidebar":"docs"},"module-2/validation-tools":{"id":"module-2/validation-tools","title":"Validation Tools for Perception & Computer Vision Module","description":"Code Example Validation"},"module-3/assignments":{"id":"module-3/assignments","title":"Module 3 Assignments","description":"Practical exercises for AI Perception & Sensor Fusion","sidebar":"docs"},"module-3/core-concepts":{"id":"module-3/core-concepts","title":"Core Concepts in AI Perception","description":"Fundamental principles of AI-based perception in robotics","sidebar":"docs"},"module-3/examples/camera-lidar-fusion":{"id":"module-3/examples/camera-lidar-fusion","title":"Camera-LiDAR Fusion Example","description":"Practical implementation of camera and LiDAR sensor fusion for robotic perception"},"module-3/examples/object-detection":{"id":"module-3/examples/object-detection","title":"Object Detection in Robotics","description":"Implementation of object detection algorithms for robotic perception"},"module-3/examples/sensor-calibration":{"id":"module-3/examples/sensor-calibration","title":"Sensor Calibration Techniques","description":"Methods for calibrating robotic sensors to ensure accurate perception"},"module-3/fusion-techniques":{"id":"module-3/fusion-techniques","title":"Sensor Fusion Techniques","description":"Methods for combining information from multiple sensors in robotic perception","sidebar":"docs"},"module-3/overview":{"id":"module-3/overview","title":"Module 3: AI Perception & Sensor Fusion","description":"Introduction to AI-based perception and sensor fusion techniques for robotics","sidebar":"docs"},"module-3/perception-algorithms":{"id":"module-3/perception-algorithms","title":"Perception Algorithms","description":"Core algorithms for object detection, tracking, and scene understanding in robotics","sidebar":"docs"},"module-3/sensors":{"id":"module-3/sensors","title":"Robotic Sensors for Perception","description":"Types, specifications, and characteristics of sensors used in robotic perception","sidebar":"docs"},"module-3/summary":{"id":"module-3/summary","title":"Module 3 Summary","description":"Summary of AI Perception & Sensor Fusion concepts and techniques","sidebar":"docs"},"module-4/advanced-techniques":{"id":"module-4/advanced-techniques","title":"Module 4: Advanced RL Techniques","description":"Deep Reinforcement Learning, policy gradients, and actor-critic methods for robotics","sidebar":"docs"},"module-4/assignments":{"id":"module-4/assignments","title":"Module 4: Assignments","description":"Reinforcement Learning and control systems assignments for robotics","sidebar":"docs"},"module-4/control-integration":{"id":"module-4/control-integration","title":"Module 4: Control Integration","description":"Combining Reinforcement Learning with traditional control systems","sidebar":"docs"},"module-4/control-systems":{"id":"module-4/control-systems","title":"Control Systems","description":"Robot control systems including PID, Model Predictive Control, feedback linearization, and mobile robot controllers"},"module-4/kinematics":{"id":"module-4/kinematics","title":"Kinematics","description":"Understanding forward and inverse kinematics, Jacobians, and kinematic chains for robot motion"},"module-4/motion-planning-algorithms":{"id":"module-4/motion-planning-algorithms","title":"Motion Planning Algorithms","description":"Graph-based and sampling-based motion planning algorithms including BFS, Dijkstra, A*, RRT, RRT*, and PRM"},"module-4/overview":{"id":"module-4/overview","title":"Module 4: Reinforcement Learning & Control","description":"Reinforcement Learning algorithms and control systems for robotics applications","sidebar":"docs"},"module-4/rl-basics":{"id":"module-4/rl-basics","title":"Module 4: RL Basics","description":"Fundamentals of Reinforcement Learning and Markov Decision Processes","sidebar":"docs"},"module-4/summary":{"id":"module-4/summary","title":"Module 4: Summary","description":"Summary of Reinforcement Learning and control systems in robotics","sidebar":"docs"},"module-4/trajectory-generation":{"id":"module-4/trajectory-generation","title":"Trajectory Generation","description":"Methods for creating smooth, time-parameterized trajectories with minimum-jerk, Bezier, and spline techniques"},"rag-chatbot/api":{"id":"rag-chatbot/api","title":"RAG Chatbot: API","description":"API design and implementation for RAG-based chatbot in robotics education","sidebar":"docs"},"rag-chatbot/architecture":{"id":"rag-chatbot/architecture","title":"RAG Chatbot Architecture","description":"System Overview"},"rag-chatbot/database-neon":{"id":"rag-chatbot/database-neon","title":"Setting up Neon Postgres Database","description":"Overview"},"rag-chatbot/deployment":{"id":"rag-chatbot/deployment","title":"RAG Chatbot: Deployment","description":"Deployment strategies and implementation for RAG-based chatbot in robotics education","sidebar":"docs"},"rag-chatbot/diagrams/backend-endpoints":{"id":"rag-chatbot/diagrams/backend-endpoints","title":"Backend API Endpoints Diagram","description":"API Endpoints Description"},"rag-chatbot/diagrams/data-flow":{"id":"rag-chatbot/diagrams/data-flow","title":"Detailed Data Flow Diagram","description":"Standard Query Flow"},"rag-chatbot/diagrams/frontend-component-interaction":{"id":"rag-chatbot/diagrams/frontend-component-interaction","title":"Frontend Chatbot Widget Interaction Diagram","description":"Interaction Flow"},"rag-chatbot/diagrams/overall-architecture":{"id":"rag-chatbot/diagrams/overall-architecture","title":"Overall RAG Chatbot Architecture Diagram","description":""},"rag-chatbot/embedding":{"id":"rag-chatbot/embedding","title":"RAG Chatbot: Embedding","description":"Embedding strategies and implementation for RAG-based chatbot in robotics education","sidebar":"docs"},"rag-chatbot/examples/backend-setup":{"id":"rag-chatbot/examples/backend-setup","title":"Backend Setup Example","description":"This example demonstrates how to set up the RAG Chatbot backend with FastAPI, including all required services and dependencies."},"rag-chatbot/examples/chat-interface":{"id":"rag-chatbot/examples/chat-interface","title":"Chat Interface Example","description":"This example demonstrates how to implement and use the chat interface with the RAG Chatbot, including conversation history, context retrieval, and response generation."},"rag-chatbot/examples/embed-document":{"id":"rag-chatbot/examples/embed-document","title":"Embed Document Example","description":"This example demonstrates how to embed a document using the RAG Chatbot backend, including chunking the document and generating vector embeddings."},"rag-chatbot/examples/query-vectorstore":{"id":"rag-chatbot/examples/query-vectorstore","title":"Query Vector Store Example","description":"This example demonstrates how to query the vector store using the RAG Chatbot backend to find similar documents based on a query."},"rag-chatbot/examples/selected-text-capture":{"id":"rag-chatbot/examples/selected-text-capture","title":"Selected Text Capture Example","description":"This example demonstrates how to capture user-selected text and send it to the RAG Chatbot backend for processing, allowing the chatbot to respond based only on the selected text."},"rag-chatbot/mcp-integration":{"id":"rag-chatbot/mcp-integration","title":"MCP Server Integration","description":"Overview"},"rag-chatbot/overview":{"id":"rag-chatbot/overview","title":"RAG Chatbot Overview","description":"What is a RAG Chatbot?"},"rag-chatbot/summary":{"id":"rag-chatbot/summary","title":"RAG Chatbot Module Summary","description":"Overview"},"rag-chatbot/ui-integration":{"id":"rag-chatbot/ui-integration","title":"RAG Chatbot: UI Integration","description":"User interface integration for RAG-based chatbot in robotics education","sidebar":"docs"},"rag-chatbot/vectorstore-qdrant":{"id":"rag-chatbot/vectorstore-qdrant","title":"Setting up Qdrant Vector Store","description":"Overview"}}}}